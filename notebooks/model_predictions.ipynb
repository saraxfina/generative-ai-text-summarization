{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f18119d-ea37-4247-9f4b-e593a103a361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd58c66-ba72-4579-9623-71833ced0307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 16:25:36.102480: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-04-25 16:25:36.102503: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-04-25 16:25:36.102508: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-04-25 16:25:36.102527: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-25 16:25:36.102539: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All TF 2.0 model weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "Some weights of BartForConditionalGeneration were not initialized from the TF 2.0 model and are newly initialized: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import BertForMaskedLM\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from rouge import Rouge\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained('facebook/bart-base', from_tf=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('../models/fine_tuned/fine_tuned_model_v2.keras/', from_tf=True)\n",
    "\n",
    "#tokenizer = BertForMaskedLM.from_pretrained('../models/fine_tuned/fine_tuned_model_v1.keras/', from_tf=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('../models/fine_tuned/fine_tuned_model_v2.keras/', from_tf=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e7af4c7-b016-4ef6-9c48-e423d85ee262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: Hersh Goldberg-Polin has been held for almost 200 daysThe parents of an Israeli-American hostage in Gaza have urged him to \"stay strong\" and \"survive\" after Hamas released a proof-of-life video.Scroll down to watch the video.Hers\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate summaries using the fine-tuned model\n",
    "new_text = \"\"\"\n",
    "\n",
    "The parents of an Israeli-American hostage in Gaza have urged him to \"stay strong\" and \"survive\" after Hamas released a proof-of-life video.\n",
    "Hersh Goldberg-Polin, 23, is seen without his lower left arm in the short clip. It was blown off during Hamas's 7 October attack on southern Israel.\n",
    "The footage is undated, but he says he has been held for almost 200 days.\n",
    "In response, his mother and father appealed for more to be done to secure a new hostage release deal.\n",
    "They urged Israel, Hamas and mediators the US, Egypt and Qatar to \"get a deal done\" to reunite \"all of us with our loved ones and end the suffering in this region\".\n",
    "Speaking under duress in the video posted on Hamas's Telegram account on Wednesday, Mr Goldberg-Polin said he needed medical help and was critical of the Israeli government's attempts to negotiate the hostages' return.\n",
    "Weeks of indirect negotiations have failed to produce an agreement, with Hamas rejecting the latest proposal for a six-week ceasefire in exchange for the release of 40 of the remaining 133 hostages. At least 30 hostages are presumed dead.\n",
    "Israel appears to be moving ahead with plans for an offensive in Rafah, southern Gaza, despite warnings of the potentially catastrophic humanitarian consequences for the 1.5 million displaced Palestinians sheltering there.\n",
    "\n",
    "\"\"\"\n",
    "encoded_text = tokenizer.encode(new_text, return_tensors=\"pt\")\n",
    "summary_ids = model.generate(encoded_text, max_length=60)\n",
    "\n",
    "\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(f\"Generated Summary: {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7c7fbf9-3f77-4aa5-9490-70a18787c300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m generated_summaries \u001b[38;5;241m=\u001b[39m predict(model, tokenizer, X_train\u001b[38;5;241m.\u001b[39mtolist())    \n\u001b[1;32m     40\u001b[0m rouge \u001b[38;5;241m=\u001b[39m Rouge()    \n\u001b[0;32m---> 41\u001b[0m rouge_scores \u001b[38;5;241m=\u001b[39m \u001b[43mrouge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_summaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/capstone/lib/python3.10/site-packages/rouge/rouge.py:103\u001b[0m, in \u001b[0;36mRouge.get_scores\u001b[0;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[1;32m     98\u001b[0m     hyps_and_refs \u001b[38;5;241m=\u001b[39m [_ \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m hyps_and_refs\n\u001b[1;32m     99\u001b[0m                      \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    100\u001b[0m                      \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    101\u001b[0m     hyps, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mhyps_and_refs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28misinstance\u001b[39m(hyps, \u001b[38;5;28mtype\u001b[39m(refs)))\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(hyps) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(refs))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m avg:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def predict(model, tokenizer, input_text):\n",
    "    \n",
    "    if isinstance(input_text, list):\n",
    "        generated_summaries = []\n",
    "        i = 0\n",
    "        for text in input_text: \n",
    "            encoded_text = tokenizer.encode(text[:2844], return_tensors=\"pt\")\n",
    "            summary_ids = model.generate(encoded_text, max_length=60)\n",
    "            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "            generated_summaries.append(summary)\n",
    "            print(i)\n",
    "            i += 1\n",
    "        \n",
    "        return generated_summaries\n",
    "        \n",
    "    elif isinstance(input_text, str):\n",
    "        encoded_text = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "        summary_ids = model.generate(encoded_text, max_length=60)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "        \n",
    "\n",
    "data = np.load('../data/dataset_cleaned.npz', allow_pickle=True)\n",
    "\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']\n",
    "X_val = data['X_val']\n",
    "y_val = data['y_val']\n",
    "\n",
    "y_test = y_test.tolist()\n",
    "\n",
    "print(len(y_test))\n",
    "\n",
    "# Define a method to perform cross-validation manually, measuring ROUGE scores\n",
    "rouge_scores = []\n",
    "\n",
    "generated_summaries = predict(model, tokenizer, X_train.tolist())    \n",
    "rouge = Rouge()    \n",
    "rouge_scores = rouge.get_scores(generated_summaries, y_train.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "304fbab4-82b8-45df-80f9-65bd1b02ad03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savez('../data/predicted_summaires.npz', y_pred=generated_summaries, rouge_scores=rouge_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd50eb21-cd53-4972-82eb-ae1c1ae868d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('../data/predicted_summaires.npz', allow_pickle=True)\n",
    "y_pred = data['y_pred']\n",
    "rouge_scores = data['rouge_scores']\n",
    "\n",
    "len(y_pred)\n",
    "len(rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4fd3476b-0d8e-470d-b5a5-c547ff0c20c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 F1_score: \t0.25952527936115555\n",
      "Rouge-1 Precision: \t0.3378454350787514\n",
      "Rouge-1 Recall: \t0.22676838785678186\n",
      "Rouge-2 F1_score: \t0.08681028835902199\n",
      "Rouge-2 Precision: \t0.11627892714562145\n",
      "Rouge-2 Recall: \t0.07651952011369734\n",
      "Rouge-l F1_score: \t0.1939511935768485\n",
      "Rouge-l Precision: \t0.25448030861230064\n",
      "Rouge-l Recall: \t0.16859916822305157\n"
     ]
    }
   ],
   "source": [
    "r_1_f = 0\n",
    "r_1_p = 0\n",
    "r_1_r = 0\n",
    "\n",
    "r_2_f = 0\n",
    "r_2_p = 0\n",
    "r_2_r = 0\n",
    "\n",
    "r_l_f = 0\n",
    "r_l_p = 0\n",
    "r_l_r = 0\n",
    "\n",
    "for item in rouge_scores:\n",
    "    if 'rouge-1' in item.keys():\n",
    "        r_1_f += item['rouge-1']['f']\n",
    "        r_1_p += item['rouge-1']['p']\n",
    "        r_1_r += item['rouge-1']['r']\n",
    "    if 'rouge-2' in item.keys():\n",
    "        r_2_f += item['rouge-2']['f']\n",
    "        r_2_p += item['rouge-2']['p']\n",
    "        r_2_r += item['rouge-2']['r']\n",
    "    if 'rouge-l' in item.keys():\n",
    "        r_l_f += item['rouge-l']['f']\n",
    "        r_l_p += item['rouge-l']['p']\n",
    "        r_l_r += item['rouge-l']['r']\n",
    "\n",
    "num_items = len(X_train)\n",
    "\n",
    "r_1_f = r_1_f / num_items\n",
    "r_1_p = r_1_p / num_items\n",
    "r_1_r = r_1_r / num_items\n",
    "\n",
    "r_2_f = r_2_f / num_items\n",
    "r_2_p = r_2_p / num_items\n",
    "r_2_r = r_2_r / num_items\n",
    "\n",
    "r_l_f = r_l_f / num_items\n",
    "r_l_p = r_l_p / num_items\n",
    "r_l_r = r_l_r / num_items\n",
    "\n",
    "\n",
    "print(\"Rouge-1 F1_score: \\t\" + str(r_1_f))\n",
    "print(\"Rouge-1 Precision: \\t\" + str(r_1_p))\n",
    "print(\"Rouge-1 Recall: \\t\" + str(r_1_r))\n",
    "print(\"Rouge-2 F1_score: \\t\" + str(r_2_f))\n",
    "print(\"Rouge-2 Precision: \\t\" + str(r_2_p))\n",
    "print(\"Rouge-2 Recall: \\t\" + str(r_2_r))\n",
    "print(\"Rouge-l F1_score: \\t\" + str(r_l_f))\n",
    "print(\"Rouge-l Precision: \\t\" + str(r_l_p))\n",
    "print(\"Rouge-l Recall: \\t\" + str(r_l_r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d1c65-3378-4e0e-a11f-8339770017d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
